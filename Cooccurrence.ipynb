{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def preprocess(newspaper=\"sun\"):\n",
    "    \"\"\"\n",
    "        Preprocesses text data from JSON files for three different newspapers (The Times, The Sun, and The Guardian),\n",
    "        including tokenisation, removal of stopwords and punctuation, part-of-speech tagging, and lemmatisation.\n",
    "        Returns a Pandas DataFrame containing the preprocessed data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        newspaper : str, default=\"sun\"\n",
    "            Name of the newspaper to preprocess data for. Must be one of \"times\", \"sun\", or \"guardian\".\n",
    "\n",
    "        Raises:\n",
    "        -------\n",
    "        ValueError:\n",
    "            If the 'newspaper' argument is not a string or is not one of the supported newspapers.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.DataFrame:\n",
    "            DataFrame containing the preprocessed text data. The DataFrame has columns for the original article content,\n",
    "            the preprocessed text, and additional columns for the sentences, tokens, part-of-speech tags, and lemmas.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(newspaper, str):\n",
    "        raise ValueError('newspaper argument must be a string')\n",
    "    newspaper = newspaper.lower()\n",
    "    if newspaper not in [\"times\", \"sun\", \"guardian\"]:\n",
    "        raise ValueError('newspaper argument must be one of \"times\", \"sun\", or \"guardian\"')\n",
    "\n",
    "    if newspaper == \"times\":\n",
    "        df = pd.read_json('times_articles.json')\n",
    "        # content = df.loc[:, \"content\"]\n",
    "\n",
    "    elif newspaper == \"sun\":\n",
    "        df = pd.read_json('sun_articles.json')\n",
    "        # content = df.loc[:, \"content\"]\n",
    "\n",
    "    elif newspaper == \"guardian\":\n",
    "        # for the guardian\n",
    "        # Create an empty list to store the contents of each JSON file\n",
    "        json_data = []\n",
    "        # Set the path to the directory containing the JSON files\n",
    "        path_to_json_files = \"crawler/guardian_articles\"\n",
    "        # Loop through each file in the directory\n",
    "        for filename in os.listdir(path_to_json_files):\n",
    "            if filename.endswith(\".json\"):\n",
    "                # Open the file and load its contents as a JSON object\n",
    "                with open(os.path.join(path_to_json_files, filename)) as f:\n",
    "                    data = json.load(f)\n",
    "                    # Append the contents to the list\n",
    "                    json_data.append(data[\"response\"][\"results\"])\n",
    "\n",
    "        new_dict_list = []\n",
    "        for item in json_data:\n",
    "            for article in item:\n",
    "                new_dict = {\n",
    "                    \"title\": article[\"webTitle\"],\n",
    "                    \"date\": article[\"webPublicationDate\"],\n",
    "                    \"content\": article[\"fields\"][\"body\"]\n",
    "                }\n",
    "                new_dict_list.append(new_dict)\n",
    "        # convert the list of dictionaries to a JSON string\n",
    "        # json_string = json.dumps(new_dict_list)\n",
    "\n",
    "        # print the JSON string\n",
    "        # print(json_string)\n",
    "        df = pd.DataFrame(new_dict_list)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Input newspaper is not processable')\n",
    "\n",
    "    # preprocessing starts here\n",
    "    df['sentences'] = df['content'].apply(lambda x: nltk.sent_tokenize(x))\n",
    "    # Tokenize each document into words and remove punctuation\n",
    "    df['tokens'] = df['content'].apply(lambda x: [word.lower() for word in word_tokenize(x) if word not in punctuation])\n",
    "    # Remove stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stopwords_list])\n",
    "    # Remove symbols\n",
    "    df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "    df['pos_tags'] = df['tokens'].apply(lambda x: nltk.pos_tag(x))\n",
    "    # Lemmatise each token\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    df['lemmas'] = df['tokens'].apply(lambda x: [lemmatiser.lemmatize(token) for token in x])\n",
    "    # Convert the list of lemmas back to text\n",
    "    df['lemmatised_text'] = df['lemmas'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_to_dtm(df):\n",
    "    \"\"\"\n",
    "       Convert a pandas DataFrame of preprocessed text data (obtained using preprocessing() ) into a Document-Term Matrix\n",
    "       (DTM) using a CountVectorizer.\n",
    "\n",
    "       Parameters:\n",
    "           df (pandas DataFrame): A DataFrame containing preprocessed text data, including a column named 'lemmatised_text'\n",
    "                                  containing the preprocessed text data as strings.\n",
    "\n",
    "       Returns:\n",
    "           pandas DataFrame: A DataFrame representation of the DTM with document IDs as the index and individual terms as\n",
    "                             columns. The cells of the DataFrame contain the term frequencies (counts) for each document.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a CountVectorizer object\n",
    "    vectoriser = CountVectorizer()\n",
    "    dtm = vectoriser.fit_transform(df['lemmatised_text'])\n",
    "    # Create a dataframe from the DTM\n",
    "    df_dtm = pd.DataFrame(dtm.toarray(), columns=vectoriser.get_feature_names_out())\n",
    "    # Add the original text column back to the dataframe\n",
    "    df_dtm['content'] = df['content']\n",
    "\n",
    "    return df_dtm\n",
    "\n",
    "\n",
    "def df_to_tfidf(df):\n",
    "    \"\"\"\n",
    "        Convert a pandas DataFrame of preprocessed text data (obtained using preprocessing() ) into a Term Frequency-Inverse\n",
    "        Document Frequency (TF-IDF) matrix using a CountVectorizer and a TfidfTransformer.\n",
    "\n",
    "        Parameters:\n",
    "            df (pandas DataFrame): A DataFrame containing preprocessed text data, including a column named 'lemmatised_text'\n",
    "                                   containing the preprocessed text data as strings.\n",
    "\n",
    "        Returns:\n",
    "            pandas DataFrame: A DataFrame representation of the TF-IDF matrix with document IDs as the index and individual\n",
    "                              terms as columns. The cells of the DataFrame contain the TF-IDF scores for each document.\n",
    "    \"\"\"\n",
    "\n",
    "    vectoriser = CountVectorizer()\n",
    "    dtm = vectoriser.fit_transform(df['lemmatised_text'])\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    tfidf = tfidf_transformer.fit_transform(dtm)\n",
    "    # Create a dataframe from the TF-IDF matrix\n",
    "    df_tfidf = pd.DataFrame(tfidf.toarray(), columns=vectoriser.get_feature_names_out())\n",
    "    df_tfidf = df_tfidf[df_tfidf.sum().sort_values(ascending=False).index]\n",
    "    # Add the original text column back to the dataframe\n",
    "    df_tfidf['content'] = df['content']\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "    # Print the resulting dataframe\n",
    "\n",
    "    return df_tfidf\n",
    "\n",
    "dataframe = preprocess(\"guardian\")\n",
    "dtm_dataframe = df_to_dtm(dataframe)\n",
    "#print(dtm_dataframe)\n",
    "print(df_to_tfidf(dataframe))\n",
    "\n",
    "corpus = df_to_tfidf(dataframe)\n",
    "\n",
    "\n",
    "def build_co_occurrence_matrix(corpus, window_size):\n",
    "    # build unique words\n",
    "    unique_words = set()\n",
    "    for text in corpus:\n",
    "        for word in word_tokenize(text):\n",
    "            unique_words.add(word)\n",
    "\n",
    "    word_search_dict = {word: np.zeros(shape=(len(unique_words))) for word in unique_words}\n",
    "    word_list = list(word_search_dict.keys())\n",
    "    for text in corpus:\n",
    "        text_list = word_tokenize(text)\n",
    "        for idx, word in enumerate(text_list):\n",
    "            # pick word in the size range\n",
    "            i = max(0, idx - window_size)\n",
    "            j = min(len(text_list) - 1, idx + window_size)\n",
    "            search = [text_list[idx_] for idx_ in range(i, j + 1)]\n",
    "            search.remove(word)\n",
    "            for neighbor in search:\n",
    "                # get neighbor idx in word_search_dict\n",
    "                nei_idx = word_list.index(neighbor)\n",
    "                word_search_dict[word][nei_idx] += 1\n",
    "    return word_search_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         world       cup      said   england      game      team    player  \\\n",
      "0     0.047536  0.046775  0.039605  0.000000  0.000000  0.013709  0.000000   \n",
      "1     0.093164  0.073338  0.020699  0.000000  0.000000  0.000000  0.000000   \n",
      "2     0.090707  0.119007  0.083971  0.000000  0.017625  0.000000  0.000000   \n",
      "3     0.046395  0.045652  0.000000  0.000000  0.010818  0.000000  0.000000   \n",
      "4     0.074733  0.073536  0.066416  0.000000  0.000000  0.000000  0.018234   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2878  0.034102  0.016778  0.028413  0.012596  0.000000  0.009834  0.010401   \n",
      "2879  0.038818  0.025464  0.028748  0.000000  0.090509  0.059704  0.047357   \n",
      "2880  0.048427  0.047651  0.013449  0.000000  0.056457  0.069828  0.014770   \n",
      "2881  0.042987  0.014100  0.095507  0.042340  0.033410  0.000000  0.087405   \n",
      "2882  0.041681  0.010253  0.046303  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "           one  football      time      year       say     would     qatar  \\\n",
      "0     0.012323  0.000000  0.012642  0.000000  0.051428  0.000000  0.062248   \n",
      "1     0.019322  0.000000  0.000000  0.041160  0.000000  0.020736  0.073200   \n",
      "2     0.000000  0.020706  0.000000  0.016698  0.000000  0.033649  0.098985   \n",
      "3     0.048110  0.025417  0.000000  0.010249  0.000000  0.061959  0.097207   \n",
      "4     0.000000  0.081884  0.000000  0.000000  0.000000  0.000000  0.117435   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2878  0.044203  0.011677  0.045347  0.160080  0.000000  0.123343  0.011164   \n",
      "2879  0.013418  0.000000  0.041295  0.014292  0.018665  0.000000  0.016944   \n",
      "2880  0.050217  0.016582  0.064396  0.026744  0.000000  0.000000  0.015854   \n",
      "2881  0.000000  0.078501  0.015243  0.047479  0.000000  0.015947  0.000000   \n",
      "2882  0.054028  0.000000  0.011085  0.069056  0.030063  0.011597  0.013645   \n",
      "\n",
      "      min    league     first      goal  australia      last      also  \\\n",
      "0     0.0  0.000000  0.000000  0.000000   0.000000  0.013789  0.028410   \n",
      "1     0.0  0.000000  0.020841  0.000000   0.000000  0.000000  0.022273   \n",
      "2     0.0  0.000000  0.000000  0.000000   0.000000  0.017541  0.036142   \n",
      "3     0.0  0.000000  0.010379  0.000000   0.000000  0.000000  0.066549   \n",
      "4     0.0  0.000000  0.000000  0.000000   0.000000  0.034685  0.017866   \n",
      "...   ...       ...       ...       ...        ...       ...       ...   \n",
      "2878  0.0  0.013819  0.028608  0.000000   0.000000  0.029676  0.040763   \n",
      "2879  0.0  0.041947  0.043419  0.041649   0.000000  0.045040  0.015467   \n",
      "2880  0.0  0.000000  0.054166  0.077937   0.000000  0.042142  0.014472   \n",
      "2881  0.0  0.023226  0.000000  0.000000   0.029152  0.033251  0.017128   \n",
      "2882  0.0  0.000000  0.011655  0.000000   0.042400  0.048362  0.012456   \n",
      "\n",
      "          club      like     match       win    people       two       get  \\\n",
      "0     0.000000  0.000000  0.000000  0.000000  0.017668  0.014380  0.000000   \n",
      "1     0.000000  0.000000  0.000000  0.000000  0.027701  0.000000  0.024887   \n",
      "2     0.000000  0.000000  0.021817  0.000000  0.000000  0.000000  0.000000   \n",
      "3     0.015563  0.047535  0.013390  0.000000  0.000000  0.011228  0.012393   \n",
      "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2878  0.014299  0.032756  0.000000  0.012007  0.063373  0.030948  0.022774   \n",
      "2879  0.000000  0.033143  0.037345  0.036447  0.000000  0.015657  0.017282   \n",
      "2880  0.000000  0.031010  0.000000  0.000000  0.000000  0.000000  0.016170   \n",
      "2881  0.000000  0.000000  0.020678  0.020181  0.000000  0.034677  0.019138   \n",
      "2882  0.000000  0.013345  0.000000  0.000000  0.046475  0.037827  0.013918   \n",
      "\n",
      "      tournament     right      back      play     final      ball       new  \\\n",
      "0       0.018522  0.033008  0.015203  0.000000  0.000000  0.000000  0.000000   \n",
      "1       0.029041  0.025877  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2       0.070687  0.041991  0.019340  0.000000  0.041824  0.000000  0.000000   \n",
      "3       0.000000  0.012887  0.000000  0.012943  0.012835  0.000000  0.000000   \n",
      "4       0.023295  0.083030  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "2878    0.000000  0.011840  0.032719  0.000000  0.000000  0.000000  0.037000   \n",
      "2879    0.000000  0.000000  0.049658  0.018049  0.017899  0.000000  0.000000   \n",
      "2880    0.000000  0.000000  0.015488  0.016888  0.000000  0.022672  0.035028   \n",
      "2881    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.062187   \n",
      "2882    0.000000  0.014472  0.000000  0.000000  0.000000  0.000000  0.060298   \n",
      "\n",
      "           fan     could     group      city     woman  southgate   country  \\\n",
      "0     0.000000  0.000000  0.018144  0.021335  0.000000        0.0  0.000000   \n",
      "1     0.061118  0.000000  0.000000  0.000000  0.000000        0.0  0.114719   \n",
      "2     0.000000  0.000000  0.000000  0.000000  0.000000        0.0  0.000000   \n",
      "3     0.000000  0.023277  0.000000  0.000000  0.000000        0.0  0.028564   \n",
      "4     0.024513  0.000000  0.000000  0.000000  0.000000        0.0  0.046011   \n",
      "...        ...       ...       ...       ...       ...        ...       ...   \n",
      "2878  0.000000  0.032080  0.000000  0.000000  0.034254        0.0  0.078734   \n",
      "2879  0.000000  0.016230  0.000000  0.000000  0.000000        0.0  0.000000   \n",
      "2880  0.039711  0.015185  0.000000  0.000000  0.024321        0.0  0.000000   \n",
      "2881  0.000000  0.000000  0.000000  0.000000  0.230286        0.0  0.000000   \n",
      "2882  0.000000  0.000000  0.000000  0.000000  0.041867        0.0  0.032078   \n",
      "\n",
      "          good       day    season     think        go      side       way  \\\n",
      "0     0.000000  0.031832  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1     0.026878  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2     0.000000  0.020247  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3     0.000000  0.000000  0.000000  0.014449  0.000000  0.000000  0.024748   \n",
      "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2878  0.024596  0.034254  0.000000  0.039828  0.060206  0.000000  0.011369   \n",
      "2879  0.018665  0.034659  0.000000  0.000000  0.000000  0.019789  0.000000   \n",
      "2880  0.000000  0.000000  0.000000  0.000000  0.000000  0.037031  0.000000   \n",
      "2881  0.000000  0.000000  0.026667  0.044627  0.020238  0.000000  0.019109   \n",
      "2882  0.030063  0.041867  0.038786  0.000000  0.000000  0.015936  0.013896   \n",
      "\n",
      "         going  ...  atasoy  freshening  mekdad  salqin  koca  roumbas  \\\n",
      "0     0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "1     0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "2     0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "3     0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "4     0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "...        ...  ...     ...         ...     ...     ...   ...      ...   \n",
      "2878  0.024932  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "2879  0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "2880  0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "2881  0.041903  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "2882  0.000000  ...     0.0         0.0     0.0     0.0   0.0      0.0   \n",
      "\n",
      "      exopected  ghebreyesus  latakia  celal  reorienting  karakas  azaz  \\\n",
      "0           0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "1           0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "2           0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "3           0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "4           0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "...         ...          ...      ...    ...          ...      ...   ...   \n",
      "2878        0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "2879        0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "2880        0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "2881        0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "2882        0.0          0.0      0.0    0.0          0.0      0.0   0.0   \n",
      "\n",
      "      wisest  then  abdulkadir  fahrettin  ahmet  maxar  ashen  gencoglu  \\\n",
      "0        0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "1        0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "2        0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "3        0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "4        0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "...      ...   ...         ...        ...    ...    ...    ...       ...   \n",
      "2878     0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "2879     0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "2880     0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "2881     0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "2882     0.0   0.0         0.0        0.0    0.0    0.0    0.0       0.0   \n",
      "\n",
      "      revolted  rumeysa  anastasiades  vafe  sabha  levent  mayadeen  kazmooz  \\\n",
      "0          0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "1          0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "2          0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "3          0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "4          0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "...        ...      ...           ...   ...    ...     ...       ...      ...   \n",
      "2878       0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "2879       0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "2880       0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "2881       0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "2882       0.0      0.0           0.0   0.0    0.0     0.0       0.0      0.0   \n",
      "\n",
      "      ersin  shoring  negligent  cuneyd  cherniavsky  suleyman  osmaniye  \\\n",
      "0       0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "1       0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "2       0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "3       0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "4       0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "...     ...      ...        ...     ...          ...       ...       ...   \n",
      "2878    0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "2879    0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "2880    0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "2881    0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "2882    0.0      0.0        0.0     0.0          0.0       0.0       0.0   \n",
      "\n",
      "      campfire  moller  tedros  dazedly  savut  seta  tunca  firat  mersin  \\\n",
      "0          0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "1          0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "2          0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "3          0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "4          0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "...        ...     ...     ...      ...    ...   ...    ...    ...     ...   \n",
      "2878       0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "2879       0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "2880       0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "2881       0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "2882       0.0     0.0     0.0      0.0    0.0   0.0    0.0    0.0     0.0   \n",
      "\n",
      "      denselow  ameliorate  ararat  depict  sassanid  \n",
      "0          0.0         0.0     0.0     0.0       0.0  \n",
      "1          0.0         0.0     0.0     0.0       0.0  \n",
      "2          0.0         0.0     0.0     0.0       0.0  \n",
      "3          0.0         0.0     0.0     0.0       0.0  \n",
      "4          0.0         0.0     0.0     0.0       0.0  \n",
      "...        ...         ...     ...     ...       ...  \n",
      "2878       0.0         0.0     0.0     0.0       0.0  \n",
      "2879       0.0         0.0     0.0     0.0       0.0  \n",
      "2880       0.0         0.0     0.0     0.0       0.0  \n",
      "2881       0.0         0.0     0.0     0.0       0.0  \n",
      "2882       0.0         0.0     0.0     0.0       0.0  \n",
      "\n",
      "[2883 rows x 50506 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_to_tfidf(dataframe))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.8 GiB for an array with shape (50297, 50297) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\2978411218.py\u001B[0m in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mXc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetdiag\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mnames\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_feature_names_out\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# This are the entity names (i.e. keywords)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mXc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'to gephi.csv'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m','\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001B[0m in \u001B[0;36mtoarray\u001B[1;34m(self, order, out)\u001B[0m\n\u001B[0;32m   1037\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0morder\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1038\u001B[0m             \u001B[0morder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_swap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'cf'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1039\u001B[1;33m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_process_toarray_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1040\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflags\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mc_contiguous\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflags\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf_contiguous\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1041\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Output array must be C or F contiguous'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001B[0m in \u001B[0;36m_process_toarray_args\u001B[1;34m(self, order, out)\u001B[0m\n\u001B[0;32m   1200\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1201\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1202\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1203\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1204\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 18.8 GiB for an array with shape (50297, 50297) and data type int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "cv = CountVectorizer(ngram_range=(1,1), stop_words = 'english')\n",
    "X = cv.fit_transform(corpus)\n",
    "Xc = (X.T * X) # matrix manipulation\n",
    "Xc.setdiag(0)\n",
    "names = cv.get_feature_names_out() # This are the entity names (i.e. keywords)\n",
    "df = pd.DataFrame(data = Xc.toarray(), columns = names, index = names)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def build_vocabulary(page:list) -> list:\n",
    "    '''\n",
    "    Builds vocabulary with all the words\n",
    "    present in the list page.\n",
    "    '''\n",
    "    vocab = list(set(page))\n",
    "    vocab.sort()\n",
    "\n",
    "    vocab_dict = {}\n",
    "    for index, word in enumerate(vocab):\n",
    "        vocab_dict[word] = index\n",
    "    return vocab_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def build_context(\n",
    "    page:str,\n",
    "    co_occurrence_vectors: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    for index, element in enumerate(page):\n",
    "        # Build start and finish of context\n",
    "        start = 0 if index-2 < 0 else index-2\n",
    "        finish = len(page) if index+2 > len(page) else index+3\n",
    "        # Retrieve Context for word\n",
    "        context = page[start:index]+page[index+1:finish]\n",
    "        for word in context:\n",
    "            # Update Co-Occurrence Matrix\n",
    "            co_occurrence_vectors.loc[element, word] = (\n",
    "                co_occurrence_vectors.loc[element, word]+1\n",
    "            )\n",
    "\n",
    "    return co_occurrence_vectors\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.0 GiB for an array with shape (50506, 50506) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\4154492152.py\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m co_occurrence_vectors = pd.DataFrame(\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvocab_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvocab_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 19.0 GiB for an array with shape (50506, 50506) and data type float64"
     ]
    }
   ],
   "source": [
    "vocab_dict = build_vocabulary(corpus)\n",
    "\n",
    "co_occurrence_vectors = pd.DataFrame(\n",
    "    np.zeros([len(vocab_dict), len(vocab_dict)]),\n",
    "    index = vocab_dict.keys(),\n",
    "    columns = vocab_dict.keys()\n",
    ")\n",
    "\n",
    "co_occurrence_vectors = build_context(\n",
    "  corpus,\n",
    "  co_occurrence_vectors\n",
    ")\n",
    "\n",
    "similarity_words = pd.DataFrame(\n",
    "    cosine_similarity(co_occurrence_vectors),\n",
    "    columns = vocab_dict.keys(),\n",
    "    index = vocab_dict.keys()\n",
    ")\n",
    "\n",
    "# Example of Top 10 words by similarity\n",
    "similarity_words.loc['qatar'].sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "world         float64\ncup           float64\nsaid          float64\nengland       float64\ngame          float64\n               ...   \ndenselow      float64\nameliorate    float64\nararat        float64\ndepict        float64\nsassanid      float64\nLength: 50506, dtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 395. KiB for an array with shape (50506,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\1651953865.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcoo_dict\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbuild_co_occurrence_matrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcorpus\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mwindow_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\3625314327.py\u001B[0m in \u001B[0;36mbuild_co_occurrence_matrix\u001B[1;34m(corpus, window_size)\u001B[0m\n\u001B[0;32m    170\u001B[0m             \u001B[0munique_words\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    171\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 172\u001B[1;33m     \u001B[0mword_search_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munique_words\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mword\u001B[0m \u001B[1;32min\u001B[0m \u001B[0munique_words\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    173\u001B[0m     \u001B[0mword_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword_search_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    174\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcorpus\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\3625314327.py\u001B[0m in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    170\u001B[0m             \u001B[0munique_words\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    171\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 172\u001B[1;33m     \u001B[0mword_search_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mword\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munique_words\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mword\u001B[0m \u001B[1;32min\u001B[0m \u001B[0munique_words\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    173\u001B[0m     \u001B[0mword_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mword_search_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    174\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcorpus\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 395. KiB for an array with shape (50506,) and data type float64"
     ]
    }
   ],
   "source": [
    "coo_dict=build_co_occurrence_matrix(corpus,window_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.50 GiB for an array with shape (2550856036,) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\3648805246.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcoo_dict\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoo_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'int'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   5813\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5814\u001B[0m             \u001B[1;31m# else, only a single dtype is given\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5815\u001B[1;33m             \u001B[0mnew_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5816\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_constructor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"astype\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5817\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    416\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"raise\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 418\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"astype\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    419\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    420\u001B[0m     def convert(\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m                     \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    326\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 327\u001B[1;33m                     \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    328\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    329\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mignore_failures\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    589\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    590\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 591\u001B[1;33m         \u001B[0mnew_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mastype_array_safe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    592\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    593\u001B[0m         \u001B[0mnew_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmaybe_coerce_values\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_values\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   1307\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1308\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1309\u001B[1;33m         \u001B[0mnew_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mastype_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1310\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mValueError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1311\u001B[0m         \u001B[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m   1255\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1256\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1257\u001B[1;33m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mastype_nansafe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1258\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1259\u001B[0m     \u001B[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m   1093\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1094\u001B[0m         \u001B[0mflat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1095\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mastype_nansafe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mskipna\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mskipna\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1096\u001B[0m         \u001B[1;31m# error: Item \"ExtensionArray\" of \"Union[ExtensionArray, ndarray]\" has no\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1097\u001B[0m         \u001B[1;31m# attribute \"reshape\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m   1166\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1167\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0missubdtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloating\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0missubdtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minteger\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1168\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mastype_float_to_int_nansafe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1169\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1170\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mis_object_dtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001B[0m in \u001B[0;36mastype_float_to_int_nansafe\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m   1214\u001B[0m             \u001B[1;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1215\u001B[0m         )\n\u001B[1;32m-> 1216\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1217\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1218\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 9.50 GiB for an array with shape (2550856036,) and data type int32"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(coo_dict,index=coo_dict.keys()).astype('int'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.0 GiB for an array with shape (50506, 50506) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\1793157507.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdataframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcoo_dict\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoo_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'int'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    612\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    613\u001B[0m             \u001B[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 614\u001B[1;33m             \u001B[0mmgr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict_to_mgr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmanager\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    615\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMaskedArray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    616\u001B[0m             \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmrecords\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmrecords\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    462\u001B[0m         \u001B[1;31m# TODO: can we get rid of the dt64tz special case above?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 464\u001B[1;33m     return arrays_to_mgr(\n\u001B[0m\u001B[0;32m    465\u001B[0m         \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtyp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtyp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    466\u001B[0m     )\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mtyp\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"block\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 135\u001B[1;33m         return create_block_manager_from_arrays(\n\u001B[0m\u001B[0;32m    136\u001B[0m             \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr_names\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconsolidate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    137\u001B[0m         )\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mcreate_block_manager_from_arrays\u001B[1;34m(arrays, names, axes, consolidate)\u001B[0m\n\u001B[0;32m   1771\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1772\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1773\u001B[1;33m         \u001B[0mblocks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_form_blocks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1774\u001B[0m         \u001B[0mmgr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBlockManager\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblocks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1775\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36m_form_blocks\u001B[1;34m(arrays, names, axes, consolidate)\u001B[0m\n\u001B[0;32m   1836\u001B[0m     \u001B[0mblocks\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mBlock\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1837\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"NumericBlock\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1838\u001B[1;33m         numeric_blocks = _multi_blockify(\n\u001B[0m\u001B[0;32m   1839\u001B[0m             \u001B[0mitems_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"NumericBlock\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconsolidate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconsolidate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1840\u001B[0m         )\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36m_multi_blockify\u001B[1;34m(tuples, dtype, consolidate)\u001B[0m\n\u001B[0;32m   1926\u001B[0m         \u001B[1;31m# \"Union[ExtensionDtype, str, dtype[Any], Type[str], Type[float], Type[int],\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1927\u001B[0m         \u001B[1;31m# Type[complex], Type[bool], Type[object], None]\"; expected \"dtype[Any]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1928\u001B[1;33m         values, placement = _stack_arrays(\n\u001B[0m\u001B[0;32m   1929\u001B[0m             \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtup_block\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m  \u001B[1;31m# type: ignore[arg-type]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1930\u001B[0m         )\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36m_stack_arrays\u001B[1;34m(tuples, dtype)\u001B[0m\n\u001B[0;32m   1955\u001B[0m     \u001B[0mshape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mfirst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1956\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1957\u001B[1;33m     \u001B[0mstacked\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1958\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1959\u001B[0m         \u001B[0mstacked\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 19.0 GiB for an array with shape (50506, 50506) and data type float64"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(coo_dict,index=coo_dict.keys()).astype('int')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Qatar World Cup whistleblower was tortured, claims family'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26732\\1549259468.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0msn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mheatmap\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\matrix.py\u001B[0m in \u001B[0;36mheatmap\u001B[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001B[0m\n\u001B[0;32m    541\u001B[0m     \"\"\"\n\u001B[0;32m    542\u001B[0m     \u001B[1;31m# Initialize the plotter object\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 543\u001B[1;33m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001B[0m\u001B[0;32m    544\u001B[0m                           \u001B[0mannot_kws\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcbar\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcbar_kws\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxticklabels\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    545\u001B[0m                           yticklabels, mask)\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\matrix.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    162\u001B[0m         \u001B[1;31m# Determine good default values for the colormapping\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 163\u001B[1;33m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001B[0m\u001B[0;32m    164\u001B[0m                                     cmap, center, robust)\n\u001B[0;32m    165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\seaborn\\matrix.py\u001B[0m in \u001B[0;36m_determine_cmap_params\u001B[1;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    196\u001B[0m         \u001B[1;31m# plot_data is a np.ma.array instance\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 197\u001B[1;33m         \u001B[0mcalc_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplot_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfilled\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnan\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    198\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mvmin\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mrobust\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'Qatar World Cup whistleblower was tortured, claims family'"
     ]
    }
   ],
   "source": [
    "sn.heatmap(dataframe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}